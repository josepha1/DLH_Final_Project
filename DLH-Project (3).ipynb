{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245992ae",
   "metadata": {},
   "source": [
    "# Contextual Embeddings from Clinical Notes Improves Prediction of Sepsis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6306237",
   "metadata": {},
   "source": [
    "## <span style = \"color:blue\">To Do</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f60f1",
   "metadata": {},
   "source": [
    "* TF-IDF\n",
    "* ~~Word2Vec~~\n",
    "* AUC for ClinicalBERT better than TF-IDF\n",
    "* Preprocessing of data\n",
    "* Look into using XGBoost as an additional classificaiton method\n",
    "* AUC and Accuracy metrics\n",
    "    * ClinicalBERT only\n",
    "    * ClinicalBERT + LSTM\n",
    "    * TF-IDF + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23783582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import h5py\n",
    "from keras import Model\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, LSTM, Softmax, Input\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch import tensor\n",
    "# from torch.nn import Softmax\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# from torch.nn import LSTM, Linear, Module\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97109d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    y = re.sub('\\\\[(.*?)\\\\]', '', x)  # remove de-identified brackets\n",
    "    y = re.sub('[0-9]+\\.', '', y)  # remove 1.2. since the segmenter segments based on this\n",
    "    y = re.sub('dr\\.', 'doctor', y)\n",
    "    y = re.sub('m\\.d\\.', 'md', y)\n",
    "    y = re.sub('admission date:', '', y)\n",
    "    y = re.sub('discharge date:', '', y)\n",
    "    y = re.sub('--|__|==', '', y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f94c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_less_n):\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].fillna(' ')\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].str.replace('\\n', ' ')\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].str.replace('\\r', ' ')\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].apply(str.strip)\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].str.lower()\n",
    "\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].apply(lambda x: preprocess(x))\n",
    "    \n",
    "    chunk_size = 140\n",
    "\n",
    "    # to get 512 words chunks for sepsis tasks\n",
    "    df_len = len(df_less_n)\n",
    "    want = pd.DataFrame({'ID': [], 'TEXT': [], 'Label': []})\n",
    "    for i in range(df_len):\n",
    "        x = df_less_n.TEXT.iloc[i].split()\n",
    "        n = int(len(x) / chunk_size)\n",
    "        for j in range(n):\n",
    "            want = want.append({'TEXT': ' '.join(x[j * chunk_size:(j + 1) * chunk_size]), 'Label': df_less_n.SEPSIS.iloc[i],\n",
    "                                'ID': df_less_n.SUBJECT_ID.iloc[i]}, ignore_index=True)\n",
    "        if len(x) % chunk_size > 10:\n",
    "            want = want.append({'TEXT': ' '.join(x[-(len(x) % chunk_size):]), 'Label': df_less_n.SEPSIS.iloc[i],\n",
    "                                'ID': df_less_n.HADM_IDleft.iloc[i]}, ignore_index=True)\n",
    "\n",
    "    return want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0dc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_notes = pd.read_csv('NOTEEVENTS.csv')\n",
    "diagnoses_icd = pd.read_csv('DIAGNOSES_ICD.csv')\n",
    "diagnoses_icd['SEPSIS'] = diagnoses_icd['ICD9_CODE'].apply(lambda x: True if x == '99591' else False) \n",
    "# diagnoses_icd[diagnoses_icd.ICD9_CODE == '99591']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9cfbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_notes_mod = clinical_notes.join(diagnoses_icd, lsuffix = 'left', rsuffix = 'right', on = 'SUBJECT_ID', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182b13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clinical_notes = clinical_notes_mod[['SUBJECT_ID', 'HADM_IDleft', 'ROW_IDleft', 'ROW_IDright', 'CATEGORY', 'DESCRIPTION', 'TEXT',\n",
    "                                        'SEPSIS', 'ICD9_CODE']]\n",
    "text = new_clinical_notes.TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cefc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = new_clinical_notes.sample(n = 200, random_state = 904)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5cbdbb",
   "metadata": {},
   "source": [
    "## <span style = \"color:blue\">TF-IDF Implementation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265061fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_sample.TEXT.to_list()\n",
    "X = corpus\n",
    "labels = df_sample.SEPSIS.tolist()\n",
    "y = labels # .tolist()\n",
    "train = ['The sky is blue.','The sun is bright.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04208d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = np.array(['\\\\','[','(','.','*','?',')', '0', '1', '2', '3', '4',\n",
    "#                         '5', '6', '7', '8', '9', '+', '.', 'dr\\.', 'doctor',\n",
    "#                        'm\\.d\\.', 'md', 'admission date:', 'discharge date:',\n",
    "#                        '--','|','__','|','=='])\n",
    "\n",
    "stop_words = np.array(['\\\\[(.*?)\\\\]', '[0-9]+\\.', 'dr\\.', 'doctor',\n",
    "                       'm\\.d\\.', 'md', 'admission date:', 'discharge date:',\n",
    "                       '--|__|=='])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d8f794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer().fit(X)\n",
    "\n",
    "tfidf_vector_X = vectorizer.transform(X).toarray()  #//shape - (3,6)\n",
    "# tfidf_vector_Y = vectorizer.transform(y).toarray() #//shape - (3,6)\n",
    "# tfidf_vector_X = tfidf_vector_X[:, :, None] #//shape - (3,6,1) \n",
    "# tfidf_vector_Y = tfidf_vector_Y[:, :, None] #//shape - (3,6,1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(tfidf_vector_X, tfidf_vector_Y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eeabede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf = tfidf_vector_X[0:160], tfidf_vector_X[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d214f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split labels into training and test sets\n",
    "y_train_tfidf, y_test_tfidf = np.array(labels[0:160]), np.array(labels[160:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a03d6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = np.reshape(X_train_tfidf, (X_train_tfidf.shape[0], 1, X_train_tfidf.shape[1]))\n",
    "X_test_tfidf = np.reshape(X_test_tfidf, (X_test_tfidf.shape[0], 1, X_test_tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8d4f24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 1, 6093)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a387a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(6093, input_shape = (None, 160)))\n",
    "model.add(Softmax())\n",
    "# model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "090db3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 6093)              152422488 \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 6093)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 152,422,488\n",
      "Trainable params: 152,422,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b05c776f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_8\" is incompatible with the layer: expected shape=(None, None, 160), found shape=(1, 1, 6093)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5828/3861481515.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_8\" is incompatible with the layer: expected shape=(None, None, 160), found shape=(1, 1, 6093)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(X_train_tfidf, y_train_tfidf, epochs = 3, batch_size = 1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ad5500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tfiddf_sepsis_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "310e2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_preds = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0b570ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6093)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8accf92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_softmax = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ba93df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       "array([0.99999994, 0.99999994, 1.0000001 , 0.9999999 , 1.        ,\n",
       "       1.        , 1.0000001 , 0.9999999 , 1.        , 1.0000001 ,\n",
       "       0.99999994, 1.        , 1.        , 0.9999999 , 0.9999999 ,\n",
       "       0.99999994, 0.9999999 , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 1.0000001 , 1.        , 0.99999994, 1.        ,\n",
       "       1.        , 0.9999998 , 1.        , 1.        , 0.9999999 ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 0.99999994, 0.9999999 , 1.0000001 , 1.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(tfidf_softmax(tfidf_preds), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43f7f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape = X_train_tfidf.shape))\n",
    "# model.add(LSTM(units = X_train_tfidf.shape[1], input_shape = X_train_tfidf.shape, return_sequences = True))\n",
    "# model.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f04afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1)                 24380     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,380\n",
      "Trainable params: 24,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.build(input_shape = (1, 160, 6093))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tfidf = y_train_tfidf.reshape((-1, 1))\n",
    "y_test_tfidf = y_train_tfidf.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61beeb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "numberOfLSTMunits = 6093\n",
    "\n",
    "input_layer = Input(shape = (1, 6093))\n",
    "hidden_state = LSTM(numberOfLSTMunits) (input_layer)\n",
    "tfidf_model = Model(inputs = input_layer, outputs = hidden_state)\n",
    "tfidf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27507e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "tfidf_model.fit(X_train_tfidf, y_train_tfidf, epochs = 3, shuffle = False, verbose = 0)\n",
    "tfidf_model.save('sepsis_model_tfidf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d149744",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 160, 6093), found shape=(32, 6093)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5828/685073791.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sepsis_model_tfidf.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 160, 6093), found shape=(32, 6093)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train_tfidf, y_train_tfidf, epochs = 3, shuffle = False, verbose = 0)\n",
    "model.save('sepsis_model_tfidf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a11ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_model = TfidfVectorizer(#ngram_range=(1, 1), # 3,5\n",
    "#                         stop_words = stop_words,  \n",
    "                        max_features = 10000)\n",
    "#                         token_pattern=r\"(?u)\\b\\w+\\b\",  \n",
    "#                         min_df = 1,\n",
    "#                         max_df = 0.9,\n",
    "#                         use_idf = 1,  \n",
    "#                         smooth_idf = 1, \n",
    "#                         sublinear_tf = 1)  \n",
    "matrix = idf_model.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5232d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da0bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f967828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e1caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f1fce0",
   "metadata": {},
   "source": [
    "## <span style = \"color:blue\">Word2Vec Implementation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc2631",
   "metadata": {},
   "source": [
    "## <span style = \"color:blue\">ClinicalBERT Implementation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950bc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "conf = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf991bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_df = preprocessing(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5671402",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row and Columns indices where the value is NaN\n",
    "null_rows, null_columns = np.where(pd.isnull(not_null_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cda4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74caa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT(inp):\n",
    "    '''\n",
    "    PARAMETERS:\n",
    "    \n",
    "    inp - Number of rows from DataFrame\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    features - Feature sets corresponding to each note\n",
    "    '''\n",
    "    tensor_list = []\n",
    "    idx_list = []\n",
    "    for j in range(inp):\n",
    "        output = []\n",
    "#         print(f'The value of j is: {j}')\n",
    "        text_df = preprocessing(df_sample[j:j + 1])\n",
    "        if not text_df.TEXT.empty:\n",
    "            # Pass each sentence to the ClinicalBERT model\n",
    "            for i in range(len(text_df.TEXT)):\n",
    "    #             print(f'*******ANALYZING TEXT*******')\n",
    "#                 print(f'The length of TEXT is: {len(text_df.TEXT)}')\n",
    "                encoding = tokenizer(text_df.TEXT[i], return_tensors = 'pt')\n",
    "                bert_output = model(**encoding)\n",
    "                last_hidden_state = bert_output['last_hidden_state']\n",
    "    #             print(f'The value of last_hidden_state is: {last_hidden_state}')\n",
    "#                 print(f'The dimensions of last_hidden_state is: {last_hidden_state.size()}')\n",
    "                output.append(last_hidden_state)\n",
    "    #             print(f'The value of output is: {output}')\n",
    "#                 print(f'The length of output is: {len(output)}')\n",
    "    #             print(f'The length of TEXT is: {len(text_df.TEXT)}')\n",
    "            out_tensor = torch.cat(output, dim = 1)\n",
    "#             out_tensor = torch.cat((torch.as_tensor(output), torch.as_tensor(df_sample.SEPSIS.iloc[j])), dim = 1)\n",
    "    #         print(f'out_tensor: {out_tensor}')\n",
    "#             print(f'The shape of out_tensor is: {out_tensor.size()}')\n",
    "            out_tensor_mean = torch.mean(out_tensor, dim = 1)\n",
    "    #         print(f'The value of out_tensor_mean is: {out_tensor_mean}')\n",
    "#             print(f'The dimensions of out_tensor_mean is: {out_tensor_mean.size()}')\n",
    "            tensor_list.append(out_tensor_mean)\n",
    "#             print(f'The number of features in tensor_list is: {len(tensor_list)}')\n",
    "            features = torch.stack(tensor_list, dim = 0)\n",
    "            print(f'The shape of features is: {features.size()}')\n",
    "        else:\n",
    "            idx_list.append(j)\n",
    "    return(features, idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da68b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = BERT(df_sample.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.drop(df_sample.index[173])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394af01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_sample.SEPSIS.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.as_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features into training and test sets\n",
    "X_train, X_test = features[0][0:160], features[0][160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split labels into training and test sets\n",
    "y_train, y_test = labels[0:160], labels[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  Linear(hidden_size, 128) #fully connected 1\n",
    "        self.fc = Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "        self.softmax = Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.softmax(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.softmax(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.detach().numpy()\n",
    "# X_train = tf.convert_to_tensor(X_train)\n",
    "# y_train = y_train.detach().numpy()\n",
    "# y_train = tf.convert_to_tensor(y_train)\n",
    "# X_test = X_test.detach().numpy()\n",
    "# X_test = tf.convert_to_tensor(X_test)\n",
    "# y_test = y_test.detach().numpy()\n",
    "# y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86ec35",
   "metadata": {},
   "source": [
    "## <span style = \"color:blue\">Define Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54961d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "numberOfLSTMunits = 160\n",
    "\n",
    "input = Input(shape = (1, 768))\n",
    "state_h = LSTM(numberOfLSTMunits) (input)\n",
    "model1 = Model(inputs = input, outputs = state_h)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = 'mse', optimizer = 'adam')\n",
    "model1.fit(X_train, y_train, epochs = 3, shuffle = False, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('sepsis_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1de7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bcc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.flatten('C').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_max = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c64e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_max(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac41c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "# Look into changing dimension which Softmax is taken.\n",
    "# model.add(Softmax())\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit(X_train, y_train, epochs = 3, shuffle = False, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('sepsis_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438bc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc80891",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5 #1000 epochs\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = features[0].size()[2] #number of features\n",
    "hidden_size = features[0].size()[2] #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 2 #number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train.shape[1]) #our lstm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.reshape(y_train, (160, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ff472",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.zeros((160, 1))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221aad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm1.forward(X_train) #forward pass\n",
    "    optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    loss.backward(retain_graph = True) #calculates the loss of the loss function\n",
    "\n",
    "    optimizer.step() #improve from loss, i.e backprop\n",
    "#     if epoch % 100 == 0:\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = lstm1(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e403e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm1(X_test) #forward pass\n",
    "    optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, y_test)\n",
    "\n",
    "    loss.backward(retain_graph = True) #calculates the loss of the loss function\n",
    "\n",
    "    optimizer.step() #improve from loss, i.e backprop\n",
    "#     if epoch % 100 == 0:\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_predict = train_predict.data.numpy() #numpy conversion\n",
    "dataY_plot = y_test.data.numpy()\n",
    "\n",
    "# data_predict = mm.inverse_transform(data_predict) #reverse transformation\n",
    "# dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "plt.figure(figsize = (10,6)) #plotting\n",
    "plt.axvline(x = 40, c = 'r', linestyle = '--') #size of the training set\n",
    "\n",
    "plt.plot(dataY_plot, label='Actual Data') #actual plot\n",
    "plt.plot(data_predict[:, 1], label='Predicted Data') #predicted plot\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(features, input_dim, hidden_dim, n_layers):\n",
    "    '''\n",
    "    PARAMETERS:\n",
    "    \n",
    "    features(tensor) - Feature sets from BERT model\n",
    "    input_dim(int) - number of expected features of input data\n",
    "    hidden_dim(int) - number of features in hidden layer\n",
    "    n_layer(int) - number of layers\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    final_out(tensor) - predicted sepsis probabilities\n",
    "    '''\n",
    "    lstm_layer = LSTM(input_dim, hidden_dim, n_layers, batch_first = False)\n",
    "    h_t = torch.zeros(1, 1, hidden_dim, dtype = torch.float32)\n",
    "    c_t = torch.zeros(1, 1, hidden_dim, dtype = torch.float32)\n",
    "    output, (h_t_new, c_t_new) = lstm_layer(features, (h_t, c_t))\n",
    "    print(f'Output: {output.mean(dim = 2)}')\n",
    "    softmax_layer = Softmax(dim = 1)\n",
    "    final_out = softmax_layer(output.mean(dim = 2))\n",
    "    print(f'Final Output: {final_out}')\n",
    "    return(final_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
